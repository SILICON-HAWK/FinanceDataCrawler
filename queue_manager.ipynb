{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86 sector links\n",
      "Processing URL: https://www.screener.in/company/compare/00000085/\n",
      "Processing URL: https://www.screener.in/company/compare/00000001/\n",
      "Processing URL: https://www.screener.in/company/compare/00000002/\n",
      "Processing URL: https://www.screener.in/company/compare/00000003/\n",
      "Processing URL: https://www.screener.in/company/compare/00000004/\n",
      "Processing URL: https://www.screener.in/company/compare/00000005/\n",
      "Processing URL: https://www.screener.in/company/compare/00000006/\n",
      "Processing URL: https://www.screener.in/company/compare/00000066/\n",
      "Processing URL: https://www.screener.in/company/compare/00000007/\n",
      "Processing URL: https://www.screener.in/company/compare/00000008/\n",
      "Processing URL: https://www.screener.in/company/compare/00000009/\n",
      "Processing URL: https://www.screener.in/company/compare/00000010/\n",
      "Processing URL: https://www.screener.in/company/compare/00000011/\n",
      "Processing URL: https://www.screener.in/company/compare/00000012/\n",
      "Processing URL: https://www.screener.in/company/compare/00000013/\n",
      "Processing URL: https://www.screener.in/company/compare/00000014/\n",
      "Processing URL: https://www.screener.in/company/compare/00000015/\n",
      "Processing URL: https://www.screener.in/company/compare/00000016/\n",
      "Processing URL: https://www.screener.in/company/compare/00000017/\n",
      "Processing URL: https://www.screener.in/company/compare/00000018/\n",
      "Processing URL: https://www.screener.in/company/compare/00000019/\n",
      "Processing URL: https://www.screener.in/company/compare/00000020/\n",
      "Processing URL: https://www.screener.in/company/compare/00000021/\n",
      "Processing URL: https://www.screener.in/company/compare/00000022/\n",
      "Processing URL: https://www.screener.in/company/compare/00000080/\n",
      "Processing URL: https://www.screener.in/company/compare/00000023/\n",
      "Processing URL: https://www.screener.in/company/compare/00000073/\n",
      "Processing URL: https://www.screener.in/company/compare/00000076/\n",
      "Processing URL: https://www.screener.in/company/compare/00000072/\n",
      "Processing URL: https://www.screener.in/company/compare/00000024/\n",
      "Processing URL: https://www.screener.in/company/compare/00000069/\n",
      "Processing URL: https://www.screener.in/company/compare/00000071/\n",
      "Processing URL: https://www.screener.in/company/compare/00000025/\n",
      "Processing URL: https://www.screener.in/company/compare/00000026/\n",
      "Processing URL: https://www.screener.in/company/compare/00000087/\n",
      "Processing URL: https://www.screener.in/company/compare/00000027/\n",
      "Processing URL: https://www.screener.in/company/compare/00000028/\n",
      "Processing URL: https://www.screener.in/company/compare/00000029/\n",
      "Processing URL: https://www.screener.in/company/compare/00000030/\n",
      "Processing URL: https://www.screener.in/company/compare/00000031/\n",
      "Processing URL: https://www.screener.in/company/compare/00000032/\n",
      "Processing URL: https://www.screener.in/company/compare/00000082/\n",
      "Processing URL: https://www.screener.in/company/compare/00000067/\n",
      "Processing URL: https://www.screener.in/company/compare/00000033/\n",
      "Processing URL: https://www.screener.in/company/compare/00000034/\n",
      "Processing URL: https://www.screener.in/company/compare/00000035/\n",
      "Processing URL: https://www.screener.in/company/compare/00000036/\n",
      "Processing URL: https://www.screener.in/company/compare/00000083/\n",
      "Processing URL: https://www.screener.in/company/compare/00000037/\n",
      "Processing URL: https://www.screener.in/company/compare/00000038/\n",
      "Processing URL: https://www.screener.in/company/compare/00000039/\n",
      "Processing URL: https://www.screener.in/company/compare/00000040/\n",
      "Processing URL: https://www.screener.in/company/compare/00000041/\n",
      "Processing URL: https://www.screener.in/company/compare/00000075/\n",
      "Processing URL: https://www.screener.in/company/compare/00000042/\n",
      "Processing URL: https://www.screener.in/company/compare/00000043/\n",
      "Processing URL: https://www.screener.in/company/compare/00000044/\n",
      "Processing URL: https://www.screener.in/company/compare/00000045/\n",
      "Processing URL: https://www.screener.in/company/compare/00000046/\n",
      "Processing URL: https://www.screener.in/company/compare/00000047/\n",
      "Processing URL: https://www.screener.in/company/compare/00000048/\n",
      "Processing URL: https://www.screener.in/company/compare/00000086/\n",
      "Processing URL: https://www.screener.in/company/compare/00000049/\n",
      "Processing URL: https://www.screener.in/company/compare/00000079/\n",
      "Processing URL: https://www.screener.in/company/compare/00000074/\n",
      "Processing URL: https://www.screener.in/company/compare/00000084/\n",
      "Processing URL: https://www.screener.in/company/compare/00000077/\n",
      "Processing URL: https://www.screener.in/company/compare/00000050/\n",
      "Processing URL: https://www.screener.in/company/compare/00000081/\n",
      "Processing URL: https://www.screener.in/company/compare/00000051/\n",
      "Processing URL: https://www.screener.in/company/compare/00000052/\n",
      "Processing URL: https://www.screener.in/company/compare/00000053/\n",
      "Processing URL: https://www.screener.in/company/compare/00000054/\n",
      "Processing URL: https://www.screener.in/company/compare/00000070/\n",
      "Processing URL: https://www.screener.in/company/compare/00000055/\n",
      "Processing URL: https://www.screener.in/company/compare/00000056/\n",
      "Processing URL: https://www.screener.in/company/compare/00000057/\n",
      "Processing URL: https://www.screener.in/company/compare/00000058/\n",
      "Processing URL: https://www.screener.in/company/compare/00000059/\n",
      "Processing URL: https://www.screener.in/company/compare/00000068/\n",
      "Processing URL: https://www.screener.in/company/compare/00000060/\n",
      "Processing URL: https://www.screener.in/company/compare/00000061/\n",
      "Processing URL: https://www.screener.in/company/compare/00000062/\n",
      "Processing URL: https://www.screener.in/company/compare/00000063/\n",
      "Processing URL: https://www.screener.in/company/compare/00000064/\n",
      "Processing URL: https://www.screener.in/company/compare/00000065/\n",
      "Queue size: 86\n",
      "Queue saved to sectors_queue.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from queue import Queue\n",
    "from urllib.parse import urljoin\n",
    "# URL of the webpage\n",
    "url = \"https://www.screener.in/explore/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save raw HTML in a variable\n",
    "    html = response.text\n",
    "base_url = \"https://www.screener.in\"  # Replace with the actual base URL\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "sector_links = soup.find_all('a', class_='bordered radius-6 padding-4-12 font-size-14 ink-700')\n",
    "\n",
    "print(f\"Found {len(sector_links)} sector links\")\n",
    "\n",
    "sectors_queue = Queue()\n",
    "\n",
    "for link in sector_links:\n",
    "    href = link.get('href')\n",
    "    absolute_url = urljoin(base_url, href)\n",
    "    print(f\"Processing URL: {absolute_url}\")\n",
    "    \n",
    "    sectors_queue.put(absolute_url)\n",
    "\n",
    "print(f\"Queue size: {sectors_queue.qsize()}\")\n",
    "\n",
    "queue_list = []\n",
    "while not sectors_queue.empty():\n",
    "    queue_list.append(sectors_queue.get())\n",
    "\n",
    "with open('sectors_queue.json', 'w') as f:\n",
    "    json.dump(queue_list, f)\n",
    "    print(\"Queue saved to sectors_queue.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "from queue import Queue\n",
    "\n",
    "\n",
    "# # Load HTML file for testing purposes. \n",
    "# with open('Aerospace & Defence Companies - Screener.htm', 'r', encoding='utf-8') as f:\n",
    "#     htmltest = f.read()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def extract_company_links(html):\n",
    "    # Load HTML file\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find all company links\n",
    "    company_links = soup.find_all('a', target=\"_blank\")\n",
    "\n",
    "    # Create a queue to hold company URLs\n",
    "    company_queue = Queue()\n",
    "\n",
    "    # Extract company URLs and add to queue\n",
    "    for link in company_links:\n",
    "        company_url = link.get('href')\n",
    "        company_queue.put(company_url)\n",
    "        logging.info(f\"Added company URL: {company_url}\")\n",
    "\n",
    "    # Print queue size\n",
    "    logging.info(f\"Queue size: {company_queue.qsize()}\")\n",
    "\n",
    "    # Convert queue to list\n",
    "    company_list = []\n",
    "    while not company_queue.empty():\n",
    "        company_list.append(company_queue.get())\n",
    "\n",
    "    return company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_visited_sectors():\n",
    "    try:\n",
    "        logging.info(\"Reading visited sectors from visited_sectors.json\")\n",
    "        with open('visited_sectors.json', 'r') as f:\n",
    "            return set(json.load(f))\n",
    "    except FileNotFoundError:\n",
    "        logging.warning(\"visited_sectors.json not found. Creating new file\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "def save_visited_sectors(visited_sectors):\n",
    "    logging.info(\"Writing visited sectors to visited_sectors.json\")\n",
    "    with open('visited_sectors.json', 'w') as f:\n",
    "        json.dump(list(visited_sectors), f, indent=4)\n",
    "    logging.info(\"Visited sectors written successfully\")\n",
    "\n",
    "\n",
    "def is_sector_visited(sector_name, visited_sectors):\n",
    "    return sector_name in visited_sectors\n",
    "\n",
    "\n",
    "def mark_sector_as_visited(sector_name, visited_sectors):\n",
    "    visited_sectors.add(sector_name)\n",
    "    save_visited_sectors(visited_sectors)\n",
    "    \n",
    "    \n",
    "def extract_sector_name(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    title_tag = soup.find('title')\n",
    "    if title_tag:\n",
    "        title = title_tag.text\n",
    "        # Remove \"- Screener\" from the title\n",
    "        sector_name = title.replace(\"- Screener\", \"\").strip()\n",
    "        return sector_name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 16:49:28,188 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,191 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,193 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,195 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,197 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,199 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,202 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,204 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,207 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,209 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,212 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,214 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,216 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,219 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,222 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,225 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,227 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,230 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,233 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,235 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,238 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,240 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,241 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,243 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,245 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,247 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,249 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,252 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,254 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,256 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,258 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,260 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,263 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,266 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,269 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,271 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,273 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,275 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,278 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,280 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,281 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,284 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,286 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,289 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,291 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,293 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,296 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,298 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,301 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,303 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,305 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,307 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,309 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,311 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,313 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,314 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,316 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,319 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,321 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,324 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,326 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,328 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,331 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,333 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,335 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,338 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,341 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,343 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,346 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,348 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,350 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,353 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,357 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,359 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,362 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,364 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,365 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,368 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,369 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,372 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,375 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,378 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,380 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,382 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,384 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:49:28,386 - INFO - Reading visited sectors from visited_sectors.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load sector URLs from JSON file\n",
    "with open('sectors_queue.json', 'r') as f:\n",
    "    sector_urls = json.load(f)\n",
    "\n",
    "\n",
    "def test(sector_urls):\n",
    "    for sector_url in sector_urls:\n",
    "        sector_name = extract_sector_name()  # Extract sector name from URL\n",
    "        \n",
    "        # Check if sector has been visited\n",
    "        visited_sectors = load_visited_sectors()\n",
    "        if is_sector_visited(sector_name, visited_sectors):\n",
    "            logging.info(f\"Skipping already visited sector: {sector_name}\")\n",
    "            continue\n",
    "\n",
    "test(sector_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queue_from_sector(sector_urls):\n",
    "    base_url = \"https://www.screener.in\"  # Replace with the actual base URL\n",
    "\n",
    "    # User-agent rotation list\n",
    "    user_agents = [\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:53.0) Gecko/20100101 Firefox/53.0',\n",
    "        'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "        'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:46.0) Gecko/20100101 Firefox/46.0'\n",
    "    ]\n",
    "\n",
    "    last_request_time = time.time()\n",
    "    max_retries = 3\n",
    "    time_interval = 15  # seconds\n",
    "\n",
    "    company_data = {}\n",
    "\n",
    "    # Iterate over sector URLs\n",
    "    for sector_url in sector_urls:\n",
    "        sector_name = sector_url.split('/')[-1]  # Extract sector name from URL\n",
    "        \n",
    "        # Check if sector has been visited\n",
    "        visited_sectors = load_visited_sectors()\n",
    "        if is_sector_visited(sector_name, visited_sectors):\n",
    "            logging.info(f\"Skipping already visited sector: {sector_name}\")\n",
    "            continue\n",
    "\n",
    "        company_data[sector_name] = []\n",
    "\n",
    "        # Add limit=50 parameter to URL\n",
    "        sector_url_with_limit = f\"{sector_url}?limit=50\"\n",
    "        \n",
    "        logging.info(f\"Visiting URL: {sector_url_with_limit}\")\n",
    "        \n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                # Calculate delay to ensure time_interval gap between requests\n",
    "                current_time = time.time()\n",
    "                time_elapsed = current_time - last_request_time\n",
    "                delay = max(0, time_interval - time_elapsed)\n",
    "                logging.info(f\"Waiting {delay} seconds before requesting...\")\n",
    "                time.sleep(delay)\n",
    "                \n",
    "                # Update last request time\n",
    "                last_request_time = time.time()\n",
    "                \n",
    "                # Randomly select user-agent\n",
    "                headers = {'User-Agent': random.choice(user_agents)}\n",
    "                \n",
    "                # Send HTTP request to sector URL\n",
    "                response = requests.get(sector_url_with_limit, headers=headers, timeout=10)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    logging.info(f\"Successful request to {sector_url_with_limit}\")\n",
    "                    \n",
    "                    # Extract sector name from HTML content\n",
    "                    sector_name = extract_sector_name(response.content)\n",
    "                    if sector_name:\n",
    "                        # Initialize company_data dictionary with correct sector_name\n",
    "                        if sector_name not in company_data:\n",
    "                            company_data[sector_name] = []\n",
    "                        \n",
    "                        # Extract company links\n",
    "                        companies = extract_company_links(response.content)\n",
    "                        company_data[sector_name].extend(companies)\n",
    "                        \n",
    "                        # Save company URLs to JSON file\n",
    "                        logging.info(f\"Saving company data to company_queue.json\")\n",
    "                        with open('company_queue.json', 'w') as f:\n",
    "                            json.dump(company_data, f, indent=4)\n",
    "                        \n",
    "                        # Mark sector as visited\n",
    "                        mark_sector_as_visited(sector_name, visited_sectors)\n",
    "                        \n",
    "                        break  # Exit loop on success\n",
    "                    else:\n",
    "                        logging.error(\"Failed to extract sector name\")\n",
    "                elif response.status_code == 429:\n",
    "                    logging.warning(f\"Rate limit exceeded for {sector_url}. Waiting 60 seconds.\")\n",
    "                    time.sleep(60)  # Wait 60 seconds before retrying\n",
    "                    retries += 1\n",
    "                else:\n",
    "                    logging.error(f\"Error {response.status_code} for {sector_url}\")\n",
    "                    retries += 1\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logging.error(f\"Request error: {e}\")\n",
    "                retries += 1\n",
    "                time.sleep(1)  # Wait 1 second before retrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 16:32:55,518 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:32:55,521 - INFO - Visiting URL: https://www.screener.in/company/compare/00000085/?limit=50\n",
      "2024-11-06 16:32:55,524 - INFO - Waiting 14.99400782585144 seconds before requesting...\n",
      "2024-11-06 16:33:11,512 - INFO - Successful request to https://www.screener.in/company/compare/00000085/?limit=50\n",
      "2024-11-06 16:33:11,615 - INFO - Added company URL: /company/HAL/\n",
      "2024-11-06 16:33:11,617 - INFO - Added company URL: /company/BEL/consolidated/\n",
      "2024-11-06 16:33:11,617 - INFO - Added company URL: /company/SOLARINDS/consolidated/\n",
      "2024-11-06 16:33:11,618 - INFO - Added company URL: /company/COCHINSHIP/\n",
      "2024-11-06 16:33:11,619 - INFO - Added company URL: /company/BDL/\n",
      "2024-11-06 16:33:11,620 - INFO - Added company URL: /company/GRSE/\n",
      "2024-11-06 16:33:11,621 - INFO - Added company URL: /company/BEML/consolidated/\n",
      "2024-11-06 16:33:11,622 - INFO - Added company URL: /company/ZENTEC/consolidated/\n",
      "2024-11-06 16:33:11,623 - INFO - Added company URL: /company/DATAPATTNS/\n",
      "2024-11-06 16:33:11,625 - INFO - Added company URL: /company/ASTRAMICRO/consolidated/\n",
      "2024-11-06 16:33:11,626 - INFO - Added company URL: /company/MIDHANI/\n",
      "2024-11-06 16:33:11,627 - INFO - Added company URL: /company/MTARTECH/\n",
      "2024-11-06 16:33:11,628 - INFO - Added company URL: /company/PARAS/consolidated/\n",
      "2024-11-06 16:33:11,629 - INFO - Added company URL: /company/AVANTEL/\n",
      "2024-11-06 16:33:11,630 - INFO - Added company URL: /company/DCXINDIA/consolidated/\n",
      "2024-11-06 16:33:11,631 - INFO - Added company URL: /company/APOLLO/\n",
      "2024-11-06 16:33:11,632 - INFO - Added company URL: /company/IDEAFORGE/\n",
      "2024-11-06 16:33:11,633 - INFO - Added company URL: /company/535136/\n",
      "2024-11-06 16:33:11,635 - INFO - Added company URL: /company/543920/\n",
      "2024-11-06 16:33:11,636 - INFO - Added company URL: /company/522229/consolidated/\n",
      "2024-11-06 16:33:11,637 - INFO - Added company URL: /company/523606/consolidated/\n",
      "2024-11-06 16:33:11,641 - INFO - Added company URL: /company/KRISHNADEF/\n",
      "2024-11-06 16:33:11,643 - INFO - Added company URL: /company/ROSSELLIND/consolidated/\n",
      "2024-11-06 16:33:11,644 - INFO - Queue size: 23\n",
      "2024-11-06 16:33:11,645 - INFO - Saving company data to company_queue.json\n",
      "2024-11-06 16:33:11,648 - INFO - Writing visited sectors to visited_sectors.json\n",
      "2024-11-06 16:33:11,651 - INFO - Visited sectors written successfully\n",
      "2024-11-06 16:33:11,652 - INFO - Reading visited sectors from visited_sectors.json\n",
      "2024-11-06 16:33:11,655 - INFO - Visiting URL: https://www.screener.in/company/compare/00000001/?limit=50\n",
      "2024-11-06 16:33:11,656 - INFO - Waiting 13.864529609680176 seconds before requesting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msectors_queue.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     sector_urls \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mget_queue_from_sector\u001b[49m\u001b[43m(\u001b[49m\u001b[43msector_urls\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 44\u001b[0m, in \u001b[0;36mget_queue_from_sector\u001b[1;34m(sector_urls)\u001b[0m\n\u001b[0;32m     42\u001b[0m delay \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, time_interval \u001b[38;5;241m-\u001b[39m time_elapsed)\n\u001b[0;32m     43\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds before requesting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Update last request time\u001b[39;00m\n\u001b[0;32m     47\u001b[0m last_request_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load sector URLs from JSON file\n",
    "with open('sectors_queue.json', 'r') as f:\n",
    "    sector_urls = json.load(f)\n",
    "\n",
    "get_queue_from_sector(sector_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacrawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
